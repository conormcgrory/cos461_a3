{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scalable Portscan Detection using Apache Spark**\n",
    "\n",
    "Network operators actively monitor their networks to protect the networks various intrusion attacks. These attackers routinely perform random `portscans` of IP addresses to find vulnerable servers to compromise. Network Intrusion Detection Systems (NIDS) attempt to detect such behavior and flag these portscanners as malicious. This assignment focuses on the Threshold Random Walk (TRW), an online algorithm that identifies malicious remote hosts. You can read the full paper [here](http://www.icir.org/vern/papers/portscan-oak04.pdf). \n",
    "\n",
    "In this assignment, you will analyze the passive network measurement data to understand the nature of malicious traffic in the campus networks. You will then simulate the performance of various online anomaly detection algorithms using the passive network measurement data. \n",
    "\n",
    "#### Traffic Measurement with IPFIX\n",
    "\n",
    "We used the Netflow data in the previous assignment to explore large voluume traffic flows and other features of network traffic. \n",
    "\n",
    "In this part of the assignment, you'll use the similar NetFlow records, but for a different type of analysis: identifying malicious network traffic.\n",
    "\n",
    "We have parsed these records into CSV (comma-separated variable) format, with the names of the fields listed in the first row of the file. (In a real network, routers export IPFIX records as binary files.) The flow records for this assignment are in the file 'netflow.csv' on Blackboard under course materials. You should download this file and place it in the directory 'assignment3/Portscan/data'.  \n",
    "\n",
    "\n",
    "#### Distributed Data Analysis with MapReduce and Apache Spark\n",
    "\n",
    "The volume of data generated by networks has become so large that it can be difficult to process the data on a single machine. Network operators can analyze more data, more quickly by relying on parallel data analysis techniques, which permits analysis of much more data and often faster responses to various network events (e.g., traffic shifts, attacks). \n",
    "\n",
    "In this assignment, you will use the Apache Spark framework to perform parallel data analysis. Apache Spark is a cluster computing technology, designed for fast computation. It is based on Hadoop MapReduce and it extends the MapReduce model to efficiently use it for more types of computations, which includes interactive queries and stream processing. \n",
    "\n",
    "This notebook has several parts. Each part starts with the instructions that you need to follow to complete the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that Spark is working\n",
    "largeRange = sc.parallelize(xrange(100000))\n",
    "reduceTest = largeRange.reduce(lambda a, b: a + b)\n",
    "filterReduceTest = largeRange.filter(lambda x: x % 7 == 0).sum()\n",
    "\n",
    "# If the Spark jobs don't work properly these will raise an AssertionError\n",
    "assert reduceTest == 4999950000\n",
    "assert filterReduceTest == 714264285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing IPFIX Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPFIX allows network devices to collect statistics about network traffic at each interface; Cisco NetFlow is a proprietary version of this standard. We have provided Cisco NetFlow data that we collected at Princeton's border router. The data is \"unsampled\"; in other words it compiles flow statistics for every packet that traverses any interface on the border router.\n",
    "\n",
    "We used the `nfdump` tool to process the raw NetFlow data that the router collected. Each line, except for the header on top and the summary information at the bottom, logs the following information for a flow:\n",
    "```\n",
    "Date first seen,Date last seen,Duration, Proto, Src IP Addr, Src Pt,Dst IPAddr, Dst Pt, Packets, Bytes, Flags, Input, Output, Router IP, Next-hop IP, BGP next-hop IP, \n",
    "Src AS, Dst AS, SMask, DMask\n",
    "```\n",
    "\n",
    "##### Setup:  Parse the NetFlow data into a Spark data structure.\n",
    "To process the data, we first need to create a Spark data structure called a resilient distributed dataset (RDD) with the name `flow_records`, where each entry in the RDD is a tuple:\n",
    "```(tstart, srcip, srcport, dstip, dstport, bytes, flag, proto)```\n",
    "\n",
    "An RDD is similar to any other structured data format, but it is designed to distribute across a cluster. In this assignment, you will manipulate your RDD locally within your virtual machine, but all of the code that you write to manipulate your RDD could in principle be distributed across a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from test_helper import Test\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('netflow.csv')\n",
    "logFile = os.path.join(baseDir, inputPath)\n",
    "\n",
    "def parseLogLine(logline):\n",
    "    \"\"\" TODO: Parse a line in the Netflow Log\n",
    "    Args:\n",
    "        logline (str): a line of text in the format:\n",
    "        Date first seen,Date last seen,Duration, Proto, Src IP Addr, Src Pt,Dst IPAddr, Dst Pt, Packets,    \n",
    "        Bytes, Flags, Input, Output, Router IP, Next-hop IP, BGP next-hop IP, Src AS, Dst AS, \n",
    "        SMask, DMask\n",
    "    Returns:\n",
    "        tuple: ((tstart, srcip, srcport, dstip, dstport, data, flag, proto), 1) for valid line,\n",
    "               or the original invalid log line and 0\n",
    "    \"\"\"\n",
    "    <>\n",
    "        \n",
    "\n",
    "def parseNetflow():\n",
    "    \"\"\" TODO: Read and parse log file \"\"\"\n",
    "\n",
    "    flow_records = <>\n",
    "    \n",
    "    return flow_records\n",
    "\n",
    "\n",
    "flow_records = parseNetflow()\n",
    "print \"Number of flow records: \", flow_records.count()\n",
    "print \"Sample flow entries: \", flow_records.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Analyzing TCP Flows**\n",
    "\n",
    "In this part of the assignment, you will analyze TCP flow records to look for a TCP SYN scan attack. A [TCP SYN scan](https://en.wikipedia.org/wiki/Port_scanner#SYN_scanning) is similar to the TCP SYN flood attack that we discussed in lecture, except that a SYN scan sends a TCP SYN packet to many _different_ destination ports to determine whether machines on the network have open ports. \n",
    "\n",
    "Let's first begin by counting the number of TCP flow records in the traffic trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tcpFlowRecords = (flow_records\n",
    "                    .filter(lambda s: str(s[7]) == 'TCP')\n",
    "                    .cache()\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TCP Flags for NetFlow Records\n",
    "\n",
    "In the previous assignment, we analyzed destinations that receive popular destinations by number of flows and by overall traffic volume. Such higher level statistics provide a coarse view of the network anomalies, but these statistics reveal less useful information about attacks and intrusion attempts. \n",
    "\n",
    "Often moderately intensive worms and other abnormal activities appear intangible amongst the immense amount of legitimate traffic that is typically found in a large enterprise network. Those malicious hosts might not show up in lists of the top senders (either by bytes or by flows), and it can be difficult to determine the exact nature of the attack traffic in advance. \n",
    "\n",
    "Certain types of attacks have other characteristic features, however: Many attackers \"scan\" a network for hosts that have processes listening for TCP connections on certain ports (i.e., in the hopes of detecting a host running a vulnerable service). These scans manifest as flows with the TCP SYN flag set.  If a NetFlow record indicates that the flow contained a TCP SYN _but no packets with the ACK flag set_, we can conclude that this flow never completed and thus may be part of a TCP SYN scan---particularly if there are a lot of these flows.\n",
    "\n",
    "\n",
    "##### TCP SYN Port Scan\n",
    "\n",
    "When an attacker sends a TCP SYN packet as part of a TCP SYN scan, each probe corresponds to one of three possible outcomes:\n",
    "- There is an active host at the destination IP address that is listening on the destination port of the SYN packet. In this case, the NetFlow record will contain both the TCP SYN and ACK flags in the flow record. These flows are difficult to distinguish from legitimate flows, because in this case a host actually answered the initial SYN. \n",
    "- There is no active host on the network at the destination IP address. In this case, we will only see TCP SYN flag. This is very different from the legitimate traffic behavior. It should be possible to identify scanner hosts analysing these flow records. \n",
    "- The destination is alive, but the port to which the SYN is sent is closed. If a client connects to a server's non-listening port, the server will send back a RST/ACK packet. According to normal TCP implementation guidelines, the host will immediately stop any TCP connection attempts once it receives a RST. The NetFlow record will only show SYN requests from the scanner host to the destination host.\n",
    "\n",
    "Let's first explore our NetFlow trace to determine whether the Princeton University campus network observes significant traffic with TCP SYN flags only (i.e., flows with TCP SYNs but no ACKs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Plot distribution of various TCP flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper scripts for plotting CDF and pie plots\n",
    "import math\n",
    "\n",
    "color_n = ['r','k','b','g','m','k','w']\n",
    "markers = ['o','*','^','s','d','3','d','o','*','^','1','4']\n",
    "linestyles = [ '-',':','--','-.','--',':','-','-.', '--',':','-','-.', \n",
    "            '--',':','-','-.', '--',':','-','-.', '--',':','-','-.']\n",
    "\n",
    "    \n",
    "\n",
    "# Plot CDFs\n",
    "def plotCDF(data, xlabel, ylabel, Xmax, Xmin, labels):\n",
    "    \"\"\" Plot CDF\n",
    "    Args:\n",
    "        data: a dict of multiple data points\n",
    "        xlabel: x-axis label\n",
    "        ylabel: y-axis label\n",
    "        Xmax: max value to plot for x-axis\n",
    "        Xmin: min value to plot for x-axis\n",
    "        labels: labels for the input data\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    xlab=[]\n",
    "    raw={}\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    p1=[]\n",
    "    legnd=[]\n",
    "    i=0\n",
    "\n",
    "    for key in labels:\n",
    "        raw[key]=data[key]\n",
    "        raw[key].sort(reverse=True)\n",
    "        num_bins=10000\n",
    "        counts, bin_edges = np.histogram(raw[key],bins=num_bins,normed=True)\n",
    "        cdf=np.cumsum(counts)\n",
    "        scale = 1.0/cdf[-1]\n",
    "        cdf=cdf*scale\n",
    "        p1.append([])\n",
    "        pl.plot(bin_edges[1:], cdf, label=key, color=color_n[i]\n",
    "                ,linestyle=linestyles[0], linewidth=3.0\n",
    "               )\n",
    "        i+=1\n",
    "\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),\n",
    "          ncol=3, fancybox=True, shadow=False)\n",
    "    pl.xlabel(xlabel)\n",
    "    pl.ylabel(ylabel)\n",
    "    if Xmin != 'N/A':\n",
    "        ax.set_xlim(xmin=Xmin)\n",
    "    if Xmax != 'N/A':\n",
    "        ax.set_xlim(xmax=Xmax)\n",
    "    ax.set_ylim(ymax=1.0)\n",
    "    ax.set_ylim(ymin=0.0)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    pass\n",
    "\n",
    "# Plot pi-charts \n",
    "def pie_pct_format(value):\n",
    "    return '' if value < 3 else '%.0f%%' % value\n",
    "\n",
    "def plot_pie_chart(fracs, labels):\n",
    "    \"\"\" Plot Pie chart\n",
    "    Args:\n",
    "        frac: a list of fractions for the pie chart\n",
    "        labels: list of labels for the input frac\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(4.5, 4.5), facecolor='white', edgecolor='white')\n",
    "    colors = ['purple', 'lightskyblue', 'yellowgreen', 'gold', 'lightcoral', 'yellow',\n",
    "             'orange','lightgreen','darkblue','pink']\n",
    "    #explode = (0.05, 0.05, 0.1, 0, 0, 0,0.1, 0, 0, 0)\n",
    "    patches, texts, autotexts = plt.pie(fracs, labels=labels, colors=colors,\n",
    "                                        #explode=explode, \n",
    "                                        autopct=pie_pct_format,\n",
    "                                        shadow=False,  startangle=250)\n",
    "    for text, autotext in zip(texts, autotexts):\n",
    "        if autotext.get_text() == '':\n",
    "            text.set_text('')  # If the slice is small to fit, don't show a text label\n",
    "    plt.legend(labels, loc=(0.80, -0.1), shadow=True)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise\n",
    "tcpFlagToCountList = <list>\n",
    "print 'Found %d TCP Flag combinations' % len(tcpFlagToCountList)\n",
    "\n",
    "# Extract frac and labels\n",
    "labels = <list>\n",
    "fracs = <list>\n",
    "\n",
    "# Plot the pie chart\n",
    "plot_pie_chart(fracs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe what the plots tells us about the number of traffic flows that contain only TCP SYN flags, with no corresponding ACK flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2: Port Scan Detection Using IPFIX Data**\n",
    "\n",
    "A network operator can analyze IPFIX data to determine which hosts are sending port scan traffic to its network. It can classify all the source IP addresses into known bad traffic flows and the remainder. \n",
    "\n",
    "- _known bad_ hosts are the one that match one or more definition of bad behavior. In this assignment we will consider hosts that try to send traffic to some know bad TCP ports. These ports are: 135/tcp, 139/tcp, 445/tcp, or 1433/tcp. These correspond to Windows RPC, NetBIOS, SMB, and SQL-Snake attacks. We expect that most of these `known_bad` hosts are scanners, but that is not necessarily true for all the `known_bad` hosts.\n",
    "\n",
    "- _remainder_ are the hosts that do not fall into teh category of `known_bad` hosts, as described above; this traffic contains both attackers who sent TCP SYN scans and benign hosts. We can observe the connectivity behavior of these hosts to determine which hosts are likely scanners and which hosts are benign. \n",
    "\n",
    "##### **Metric 1: Number of unique destination IP addresses with failed connections.**\n",
    "\n",
    "Let's first detect likely SYN scan attackers by identifying remote hosts that make failed connection attempts (i.e., flows with only the SYN flag set, with no ACK flag ever set) to a large number of IP addresses. We'll compare the distribution of the number of distinct IP addresses accessed by `known_bad` vs. those accessed by the `remainder` by looking at a cumulative distribution function (CDF). (A CDF is a common way for network analysts to understand the distribution of various traffic characteristics.)\n",
    "\n",
    "The `remainder` hosts comprise both `scanners` and `benign` hosts. Thus, we expect the CDF to show two pronounced modalities, corresponding to each of these classes of hosts. \n",
    "\n",
    "**Note**: Although the NetFlow collector at Princeton University is downstream of the campus intrustion detection system, we are unsure of what that device blocks are permits because we do not know its exact configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_bad_ports = {135,139,445,1433}\n",
    "badSrc_2_inactiveDst = <rdd>\n",
    "badSrc_2_inactiveDst = <rdd>\n",
    "\n",
    "print badSrc_2_inactiveDst.take(10), badSrc_2_inactiveDst.count()\n",
    "print remainderSrc_2_inactiveDst.take(10), remainderSrc_2_inactiveDst.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "labels = [\"known_bad\", \"remainder\"]\n",
    "plot_data[\"known_bad\"] = [math.log(x[1],10) for x in bad_src_2_inactiveDst.collect()]\n",
    "plot_data[\"remainder\"] = [math.log(x[1],10) for x in remainder_src_2_inactiveDst.collect()]\n",
    "plotCDF(plot_data, \"log(# of unique IP addresses)\", \"CDF\", 'N/A', 0, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe two modes in the conenctivity behavior for the `remainder` hosts. Also, if you see multiple modes among the `known_bad` hosts, think about what those multiple modes might reflect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### **Metric 2: Percentage of unique IP addresses with failed connections.**\n",
    "\n",
    "Another metric that can help detect a SYN scan is the percentage of destination IP addresses that a given source IP address has accessed for which the connection attempt failed; we define this metric as `inactive_pct`. \n",
    "\n",
    "We will now compare this metric for both hosts in each of the `remainder` and `known_bad` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badSrc_2_inactive_pct = <rdd>\n",
    "remainderSrc_2_inactive_pct = <rdd>\n",
    "\n",
    "print badSrc_2_inactive_pct.take(10), badSrc_2_inactive_pct.count()\n",
    "print remainderSrc_2_inactive_pct.take(10), remainderSrc_2_inactive_pct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data = {}\n",
    "labels = [\n",
    "          \"remainder\", \"known_bad\"\n",
    "         ]\n",
    "plot_data[\"known_bad\"] = [(x[1],10) for x in badSrc_2_inactive_pct.collect()]\n",
    "plot_data[\"remainder\"] = [(x[1],10) for x in remainderSrc_2_inactive_pct.collect()]\n",
    "plotCDF(plot_data, \"inactive-pct\", \"CDF\", 100, 0, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see two modes in the connection behavior of hosts in the `remainder` class.\n",
    "\n",
    "##### Enumerate different types of hosts\n",
    "\n",
    "Based on this observation, you should determine a threshold for the percentage of failed connections to identify attackers. Suppose that this threshold is _T_. \n",
    "\n",
    "So we will enumerate the following three classes of hosts:\n",
    "- `known_bad`: as defined above.\n",
    "- `benign`: hosts in `remainder` with `inactive-pct` less than or equal to threshold T.\n",
    "- `suspect`: hosts in `remainder` with `inactive-pct` greater than threshold T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_bad_srcs = []\n",
    "benign_srcs = []\n",
    "suspect_srcs = []\n",
    "\n",
    "print \"Number of known_bad sources:\", len(known_bad_srcs)\n",
    "print \"Number of benign sources:\", len(benign_srcs)\n",
    "print \"Number of suspect sources:\", len(suspect_srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3: Online Port Scan Detection**\n",
    "\n",
    "The previous part of the assignment performed detection of SYN scans using offline NetFlow traces. Computing each of the statistics that we looked at would require capturing and analyzing the complete trace, as opposed to computing an \"online\" statistic that updated based on an incoming stream of data. \n",
    "\n",
    "In this part of the assignment, you will implement two _online_ port scan detection algorithms that can detect \n",
    "\n",
    "- Bro's Port Scan Detection Algorithm\n",
    "- TRW Port Scann Detection Algorithm\n",
    "\n",
    "#### **Bro's Port Scan Detection Algorithm**\n",
    "\n",
    "Bro's detection algorithm builds on the same intution that failed connection attempts are good indicators for identifying scans. As we have already discussed, because scanners have little knowledge of network topology and system configuration, they are likely to often choose an IP address or port that is not active. \n",
    "\n",
    "The algorithm itself treats connection attempts different depending on each service. IF the connection attempt corresponds to a service specified in a list enumerated in the configuration, Bro only performs bookkeeping for failed connection attempts (i.e., a SYN that either does not receive an ACK or receives a RST).\n",
    "\n",
    "Bro then tracks all other connection attempts for unspecified services, whether or not the attempt failed or succeeded. Bro sums the number of distinct destination addresses for connection attempts from any given source address. If the number exceeds some threshold, _T_, Bro flags the source address as a scanner.\n",
    "\n",
    "By default, Bro sets T = 100 addresses and the set of services for which only failures are considered to HTTP (80), SSH (22), Telnet (23), SMTP (25), IDENT (113), FTP (20), and Gopher (70). \n",
    "\n",
    "##### Exercise: Implement Bro's port scan detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_netflow_log_bro(tmp):\n",
    "    srcip = tmp[6]\n",
    "    dstip = tmp[8]\n",
    "    flag = tmp[12]\n",
    "    dstport = int(tmp[9])\n",
    "    if flag == '.A..S.':\n",
    "        return (srcip, dstip, dstport, 1)\n",
    "    else:\n",
    "        return (srcip, dstip, dstport, 0)\n",
    "    \n",
    "def bro_portscan_detection(fname, ports_considered, Thresh):\n",
    "    # dict of src IP to # of failed connections to \"ports_considered\"\n",
    "    failure_counter = {}\n",
    "    # disct of scanner IP address to # of failed connections to \"ports_considered\"\n",
    "    scanners = {}\n",
    "    # implement the detection logic\n",
    "    <use process_netflow_log_bro() function>\n",
    "    return scanners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now observe the sensitivity of this port scan detection algorithm to the `threshold` variable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TCP ports only\n",
    "ports_considered = [80, 22, 23, 25, 113, 20, 70]\n",
    "thresolds = [1,2,4,8,16,32,64,128]\n",
    "x = []\n",
    "y = []\n",
    "for T in thresolds:\n",
    "    scanners = bro_portscan_detection(logFile, ports_considered, T)\n",
    "    print T, len(scanners.keys())\n",
    "    x.append(T)\n",
    "    y.append(len(scanners.keys()))  \n",
    "f, (ax1) = plt.subplots(1)\n",
    "ax1.plot(x, y ,color='k')\n",
    "ax1.grid(True)\n",
    "plt.xlabel('Thresold (T)')\n",
    "plt.ylabel('# of Scanners')\n",
    "ax1.set_ylim(ymin=0.0)\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 4 # is this choice of threshold reasonable?\n",
    "bro_scanners = bro_portscan_detection(logFile, ports_considered, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Justify the choice of parameter T = 4 for TRW port scan detection? \n",
    "<Your answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TRW Port Scan Detection Algorithm**\n",
    "\n",
    "The _Threshold Random Walk (TRW)_ port scan detection algorithm builds on the intuition that a scanner is more likely than a legitimate host make connection attempts to destination IP addresses that either are unresponsive to that connection attempt (either because there is no host at the address, or because the host is not listening on the specified port). \n",
    "\n",
    "In contrast to Bro, whose threshold is hard-coded, the TRW port scan detection algorithm has a tunable threshold based on maximum likelihood ratios. It maintains a counter that continually increases (or respectively, decreases) its respective conditional probabilities of the host being a scanner, given a certain number of failed (or respectively, successful) connection attempts. This continual adjustment of the conditional probability gives the detection algorithm its name of Treshold Random Walk.\n",
    "\n",
    "TRW the basis for an online algorithm whose goal is to reduce the number of observed connection attempts required to detect the scanner (compared to, say, Bro's scan detection algorithm), while bounding the missed detection and false positive probabilities.\n",
    "\n",
    "#### Exercise: Implement TRW port scan detection algorithm as described in this [paper](http://www.icir.org/vern/papers/portscan-oak04.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_netflow_log_trw(tmp):\n",
    "    srcip = tmp[6]\n",
    "    dstip = tmp[8]\n",
    "    flag = tmp[12]\n",
    "    if flag == '.A..S.':\n",
    "        return (srcip, dstip, 1)\n",
    "    else:\n",
    "        return (srcip, dstip, 0)\n",
    "    \n",
    "def trw_portscan_detection(fname, Pd, Pf, theta1, theta0):\n",
    "    # D[s] is the list of distinct IP addresses to which s has previously made connections\n",
    "    D = {}\n",
    "    \n",
    "    # S[s] reflects the decision state, one of: PENDING (2);H0 (0); or H1 (1)\n",
    "    # in other words, \n",
    "    # S[s] = 2 => PENDING state,\n",
    "    # S[s] = 1 => H1 is true, and \n",
    "    # S[s] = 0 => H0 is true\n",
    "    S = {}\n",
    "    \n",
    "    # L[s] is the likelihood ratio for s\n",
    "    L = {}\n",
    "    \n",
    "    # upper thresold\n",
    "    eta1 = Pd/Pf\n",
    "    \n",
    "    # lower thresold\n",
    "    eta0 = (1-Pd)/(1-Pf)\n",
    "    \n",
    "    \n",
    "    # implement the detection logic\n",
    "    <use process_netflow_log_trw() function>\n",
    "    \n",
    "    # Enumerate different types of hosts\n",
    "    pending_hosts = []\n",
    "    H1 = []\n",
    "    H0 = []\n",
    "    for source in S:\n",
    "        if S[source] == 2:\n",
    "            pending_hosts.append(source)\n",
    "        elif S[source] == 1:\n",
    "            H1.append(source)\n",
    "        else:\n",
    "            H0.append(source)\n",
    "    return pending_hosts, H1, H0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now observe the sensitivity of the TRW port scan detection algorithm to the \n",
    "`detection probability (Pd)` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta1 = 0.1\n",
    "theta0 = 0.9\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# Tuning detection probability\n",
    "Pds = range(80,102,2)\n",
    "for Pd in Pds:\n",
    "    Pf = 0.09\n",
    "    Pd = float(Pd)/100\n",
    "    pending_hosts, H1, H0 = trw_portscan_detection(logFile, Pd, Pf, theta1, theta0)\n",
    "    x.append(Pd)\n",
    "    y.append(len(H1))\n",
    "    #print Pf, Pd, len(H1)\n",
    "\n",
    "f, (ax1) = plt.subplots(1)\n",
    "ax1.plot(x, y ,color='k')\n",
    "ax1.grid(True)\n",
    "plt.xlabel('Detection Probability')\n",
    "plt.ylabel('# of Scanners')\n",
    "#ax1.set_xlim(xmin=0.0)\n",
    "ax1.set_ylim(ymin=0.0)\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now observe the sensitivity of this port scan detection algorithm to the \n",
    "`false alarm rate (Pf)` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning false alarm rate\n",
    "x = []\n",
    "y = []\n",
    "# false alarm rate\n",
    "Pfs = range(1,11,1)\n",
    "for Pf in Pfs:\n",
    "    Pf = float(Pf)/100\n",
    "    Pd = 0.9\n",
    "    pending_hosts, H1, H0 = trw_portscan_detection(logFile, Pd, Pf, theta1, theta0)\n",
    "    x.append(Pf)\n",
    "    y.append(len(H1))\n",
    "    #print Pf, Pd, len(H1)\n",
    "    \n",
    "f, (ax1) = plt.subplots(1)\n",
    "ax1.plot(x, y ,color='k')\n",
    "ax1.grid(True)\n",
    "plt.xlabel('False Alarm Rate')\n",
    "plt.ylabel('# of Scanners')\n",
    "#ax1.set_xlim(xmin=0.0)\n",
    "ax1.set_ylim(ymin=0.0)\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pd = 0.90 # is this choice of Pd reasonable?\n",
    "Pf = 0.05 # is this choice of Pf reasonable?\n",
    "pending_hosts, H1, H0 = trw_portscan_detection(logFile, Pd, Pf, theta1, theta0)\n",
    "trw_scanners = H1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify the choice of parameters Pf=0.05 and Pd=0.90 for TRW port scan detection.\n",
    "\n",
    "<Your answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"suspect_sources \", len(suspect_srces)\n",
    "print \"bro identified scanners \", len(bro_scanners)\n",
    "print \"trw identified scanners \", len(trw_scanners)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
